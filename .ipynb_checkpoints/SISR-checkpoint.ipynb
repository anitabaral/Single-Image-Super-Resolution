{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-oupmpexOpsx"
   },
   "source": [
    "%tensorflow_version 1.x\n",
    "Import all the required modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "OGoQfCEvOd55",
    "outputId": "93fe4573-4d8a-449f-e9fa-55ae944b44cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 1.x\n",
    "\n",
    "# %matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, BatchNormalization, Dense, Flatten, Input, UpSampling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.models import Model\n",
    "from keras.layers import add\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0lbQKJJPSth"
   },
   "source": [
    " Overall Network Layout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PR_bVDIXO6Yy"
   },
   "outputs": [],
   "source": [
    "#Residual block\n",
    "def res_block_gen(model, kernel_size, filters, strides):\n",
    "    res_gen = model\n",
    "    model = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same')(model)\n",
    "    model = BatchNormalization(momentum=0.5)(model)\n",
    "\n",
    "    model = PReLU(alpha_initializer=\"zeros\",\n",
    "                  alpha_regularizer=None,\n",
    "                  alpha_constraint=None,\n",
    "                  shared_axes=[1, 2])(model)\n",
    "\n",
    "    model = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "\n",
    "    model = add([res_gen, model])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zi4ErkGBPoyR"
   },
   "outputs": [],
   "source": [
    "#up_scaling_block\n",
    "def up_scale(model, kernel_size, filters, strides):\n",
    "\n",
    "    model = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same')(model)\n",
    "    model = UpSampling2D(size=2)(model)\n",
    "    model = PReLU()(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pa0E_GBcPqqC"
   },
   "outputs": [],
   "source": [
    "#Discriminator block\n",
    "def disc(model, filters, kernel_size, strides):\n",
    "    model = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9o7hEwYBPta_"
   },
   "outputs": [],
   "source": [
    "# Discriminator Network\n",
    "class dis():\n",
    "    def __init__(self, image_shape):\n",
    "        self.image_shape = image_shape\n",
    "        print('self.image_shape')\n",
    "\n",
    "    def discriminator(self):\n",
    "        dis_input = Input(self.image_shape)\n",
    "        print(dis_input)\n",
    "\n",
    "        model = Conv2D(filters=64, kernel_size=3, strides=1,\n",
    "                       padding='same')(dis_input)\n",
    "        model = Activation('relu')(model)\n",
    "\n",
    "        model = disc(model, 64, 3, 2)\n",
    "        model = disc(model, 128, 3, 1)\n",
    "\n",
    "\n",
    "class gen(object):\n",
    "    def __init__(self, noise_shape):\n",
    "        self.noise_shape = noise_shape\n",
    "\n",
    "    def generator(self):\n",
    "\n",
    "        gen_input = Input(self.noise_shape)\n",
    "\n",
    "        model = Conv2D(filters=64, kernel_size=9, strides=1,\n",
    "                       padding='same')(gen_input)\n",
    "        model = PReLU(alpha_initializer='zeros',\n",
    "                      alpha_regularizer=None,\n",
    "                      alpha_constraint=None,\n",
    "                      shared_axes=[1, 2])(model)\n",
    "        gen_model = model\n",
    "\n",
    "        for index in range(16):\n",
    "            model = res_block_gen(model, 3, 64, 1)\n",
    "\n",
    "        model = Conv2D(filters=64, kernel_size=3, strides=1,\n",
    "                       padding=\"same\")(model)\n",
    "        model = BatchNormalization(momentum=0.5)(model)\n",
    "        model = add([gen_model, model])\n",
    "\n",
    "        # Using 2 UpSampling\n",
    "        for index in range(2):\n",
    "            model = up_scale(model, 3, 256, 1)\n",
    "        # print('model',model)\n",
    "\n",
    "        model = Conv2D(filters=3, kernel_size=9, strides=1,\n",
    "                       padding='same')(model)\n",
    "        model = Activation('tanh')(model)  #modification\n",
    "\n",
    "        # print('model',model)\n",
    "\n",
    "        generator = Model(inputs=gen_input, outputs=model)\n",
    "        # print('generator',generator)\n",
    "        return generator\n",
    "\n",
    "        model = disc(model, 128, 3, 2)\n",
    "        model = disc(model, 256, 3, 1)\n",
    "        model = disc(model, 256, 3, 2)\n",
    "        model = disc(model, 512, 3, 1)\n",
    "        model = disc(model, 512, 3, 2)\n",
    "\n",
    "        model = Flatten()(model)\n",
    "        model = Dense(1024)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "\n",
    "        model = Dense(1)(model)\n",
    "        model = Activation('sigmoid')(model)\n",
    "\n",
    "        discriminator = Model(input=dis_input, output=model)\n",
    "        return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WfX8czQP8bQ"
   },
   "outputs": [],
   "source": [
    "# Discriminator Network\n",
    "class dis():\n",
    "    def __init__(self, image_shape):\n",
    "        self.image_shape = image_shape\n",
    "        print('self.image_shape')\n",
    "\n",
    "    def discriminator(self):\n",
    "        dis_input = Input(self.image_shape)\n",
    "        print(dis_input)\n",
    "\n",
    "        model = Conv2D(filters=64, kernel_size=3, strides=1,\n",
    "                       padding='same')(dis_input)\n",
    "        model = Activation('relu')(model)\n",
    "\n",
    "        model = disc(model, 64, 3, 2)\n",
    "        model = disc(model, 128, 3, 1)\n",
    "        model = disc(model, 128, 3, 2)\n",
    "        model = disc(model, 256, 3, 1)\n",
    "        model = disc(model, 256, 3, 2)\n",
    "        model = disc(model, 512, 3, 1)\n",
    "        model = disc(model, 512, 3, 2)\n",
    "\n",
    "        model = Flatten()(model)\n",
    "        model = Dense(1024)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "\n",
    "        model = Dense(1)(model)\n",
    "        model = Activation('sigmoid')(model)\n",
    "\n",
    "        discriminator = Model(input=dis_input, output=model)\n",
    "        return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x9DCGuCYQGx7"
   },
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZKPWJTjZQDr0",
    "outputId": "2b3fb452-ff40-43f0-f25a-e671fd3ccf4e"
   },
   "outputs": [],
   "source": [
    "# #Mount the drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TldTgbZyQWS8"
   },
   "outputs": [],
   "source": [
    "train_path = \"./data/train/\"\n",
    "test_path = \"./data/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "DybQ147UQhJ3",
    "outputId": "c0117a10-8774-4503-f7cb-4823ec0c2f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dt_train_1.jpg', 'dt_train_10.jpg', 'dt_train_11.jpg', 'dt_train_12.jpg', 'dt_train_13.jpg', 'dt_train_14.jpg', 'dt_train_15.jpg', 'dt_train_16.jpg', 'dt_train_17.jpg', 'dt_train_18.jpg', 'dt_train_19.jpg', 'dt_train_2.jpg', 'dt_train_20.jpg', 'dt_train_21.jpg', 'dt_train_22.jpg', 'dt_train_23.jpg', 'dt_train_24.jpg', 'dt_train_25.jpg', 'dt_train_26.jpg', 'dt_train_27.jpg', 'dt_train_28.jpg', 'dt_train_29.jpg', 'dt_train_3.jpg', 'dt_train_30.jpg', 'dt_train_31.jpg', 'dt_train_32.jpg', 'dt_train_33.jpg', 'dt_train_34.jpg', 'dt_train_35.jpg', 'dt_train_36.jpg', 'dt_train_37.jpg', 'dt_train_38.jpg', 'dt_train_39.jpg', 'dt_train_4.jpg', 'dt_train_40.jpg', 'dt_train_41.jpg', 'dt_train_42.jpg', 'dt_train_43.jpg', 'dt_train_44.jpg', 'dt_train_45.jpg', 'dt_train_46.jpg', 'dt_train_47.jpg', 'dt_train_48.jpg', 'dt_train_49.jpg', 'dt_train_5.jpg', 'dt_train_50.jpg', 'dt_train_6.jpg', 'dt_train_7.jpg', 'dt_train_8.jpg', 'dt_train_9.jpg']\n",
      "total train images: 50\n",
      "total test images: 10\n"
     ]
    }
   ],
   "source": [
    "trainfile_name = os.listdir(train_path)\n",
    "print(trainfile_name)\n",
    "num = len(trainfile_name)\n",
    "print(\"total train images:\", num)\n",
    "testfile_name = os.listdir(test_path)\n",
    "num = len(testfile_name)\n",
    "print(\"total test images:\", num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcrnffXbQit7"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    return train_images\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#load the train_data from drive\n",
    "def load_train_data ():\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    \n",
    "    train_path =\"./data/train/\"\n",
    "    test_path =\"./data/test/\" \n",
    "    train_data = os.listdir(train_path)\n",
    "    test_data = os.listdir(test_path)\n",
    "    \n",
    "    for sample in train_data:\n",
    "        img_path = train_path + sample\n",
    "        train_hr_images = cv2.imread(img_path)\n",
    "        train_images.append(train_hr_images)\n",
    "  #  print(train_hr_images)   \n",
    "   return train_images\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJdRlVYSQ2hG"
   },
   "outputs": [],
   "source": [
    "\n",
    "def hr_images(images):\n",
    "  # images_hr = tf.keras.preprocessing.image.img_to_array(images)  \n",
    "  images_hr = np.array(images)\n",
    "  return images_hr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kmx7iVRUQ5-q"
   },
   "outputs": [],
   "source": [
    "def lr_images(real_images, downscale):\n",
    "   images =[]\n",
    "   for img in range(len(real_images)):\n",
    "        images.append(np.array(PIL.Image.fromarray(real_images[img]).resize([real_images[img].shape[0]//downscale, \n",
    "        real_images[img].shape[1]//downscale],resample=PIL.Image.BICUBIC)))\n",
    "   images_lr = np.array(images)\n",
    "    \n",
    "    \n",
    "   return images_lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wfJdb3iQ7cT"
   },
   "outputs": [],
   "source": [
    "def normalize(input_data):\n",
    "    input_data = np.divide(input_data.astype(np.float32),127.5) - np.ones_like(input_data, dtype=np.float32)\n",
    "    # print(\"ii\",input_data)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8n2xKLLAQ9EX"
   },
   "outputs": [],
   "source": [
    "def denormalize(input_data):\n",
    "    input_data = input_data*127.5+127.5\n",
    "    return input_data.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJYWd70LQ_Mr"
   },
   "outputs": [],
   "source": [
    "def resize_images(img):\n",
    "\n",
    "  img_size = 192\n",
    "  resized_images =[]\n",
    "  for i in range(len(img)):\n",
    "    resized_images.append(np.array(PIL.Image.fromarray(img[i]).resize([img_size, img_size],resample=PIL.Image.BICUBIC)))\n",
    "        \n",
    "  resized_images = np.array(resized_images)\n",
    "  return resized_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsmPM9S9RDEA"
   },
   "outputs": [],
   "source": [
    "def train_data_load():\n",
    "  x_train = load_train_data()\n",
    "\n",
    "  # conversion of image into the numpy array\n",
    "  x_train_hr = hr_images(x_train)\n",
    "  x_train_hr_resized =resize_images(x_train_hr)\n",
    "  x_train_hr = normalize(x_train_hr_resized) #normailze the array\n",
    "  \n",
    "  #conversion of hr images into lr_images and into the numpy array\n",
    "  x_train_lr = lr_images(x_train_hr_resized, 4)\n",
    "  # x_train_lr_resized =resize_images(x_train_lr)\n",
    "\n",
    "  x_train_lr = normalize(x_train_lr) #array normalization\n",
    "\n",
    "\n",
    "  return x_train_hr , x_train_lr \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HvaT9VAnRFbp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_test_data ():\n",
    "   test_images = []\n",
    "    \n",
    "   test_path =\"/content/drive/My Drive/Colab Notebooks/project/dataset-upload-to-kaggle/finished/valid/dataraw/hires/\"  \n",
    "   test_data = os.listdir(test_path)\n",
    "    \n",
    "   for sample in test_data:\n",
    "        img_path = test_path + sample\n",
    "        test_hr_images = cv2.imread(img_path)\n",
    "        test_images.append(test_hr_images)\n",
    "      \n",
    "   return test_images\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOUIXrLbRJii"
   },
   "outputs": [],
   "source": [
    "def load_testing_data():\n",
    "  x_test = load_test_data()\n",
    "\n",
    "  # conversion of image into the numpy array\n",
    "  x_test_hr = hr_images(x_test)\n",
    "  x_test_hr_resized =resize_images(x_test_hr)\n",
    "\n",
    "  x_test_hr = normalize(x_test_hr_resized) #normailze the array\n",
    "  \n",
    "  #conversion of hr images into lr_images and into the numpy array\n",
    "  x_test_lr = lr_images(x_test_hr_resized, 4)\n",
    "  # x_test_lr_resized =(x_test_lr)\n",
    "\n",
    "  x_test_lr = normalize(x_test_lr) #array normalization\n",
    "\n",
    "\n",
    "  return x_test_hr , x_test_lr\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NmM900eMRb0M"
   },
   "outputs": [],
   "source": [
    "def plot_generated_images(epoch,generator,x_test_hr,x_test_lr ,examples=3 , dim=(1, 3), figsize=(15, 5)):\n",
    "    \n",
    "    rand_nums = np.random.randint(0, x_test_hr.shape[0], size=examples)\n",
    "    image_batch_hr = denormalize(x_test_hr[rand_nums])\n",
    "    image_batch_lr = x_test_lr[rand_nums]\n",
    "    gen_img = generator.predict(image_batch_lr)\n",
    "    generated_image = denormalize(gen_img)\n",
    "    image_batch_lr = denormalize(image_batch_lr)\n",
    "    \n",
    "    #generated_image = deprocess_HR(generator.predict(image_batch_lr))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    plt.subplot(dim[0], dim[1], 1)\n",
    "    plt.imshow(image_batch_lr[1], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "        \n",
    "    plt.subplot(dim[0], dim[1], 2)\n",
    "    plt.imshow(generated_image[1], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(dim[0], dim[1], 3)\n",
    "    plt.imshow(image_batch_hr[1], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/gan_generated_image_epoch_%d.png' % epoch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RW4mepbqRhtq"
   },
   "source": [
    "Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9J4Z9NYjRfNh"
   },
   "outputs": [],
   "source": [
    "#loss calculation ------- \n",
    "class VGG_LOSS(object):\n",
    "\n",
    "    # image_shape =(64,64,3)\n",
    "    def __init__(self,image_shape):\n",
    "        self.image_shape = image_shape\n",
    "    \n",
    "    def vgg_loss(self,y_true,y_pred):\n",
    "        loss = VGG19(include_top = False,weights = 'imagenet',input_shape = self.image_shape)\n",
    "                    \n",
    "        loss.trainable = False\n",
    "        for l in loss.layers:\n",
    "          l.trainable = False\n",
    "        model = Model(inputs= loss.input,outputs= loss.get_layer('block5_conv4').output)\n",
    "        model.trainable= False\n",
    "\n",
    "        return K.mean(K.square(model(y_true)-model(y_pred)))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7p4kX5KRjqb"
   },
   "outputs": [],
   "source": [
    "def optimizer():\n",
    "    adam = Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999,epsilon = 1e-7)\n",
    "    return adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYkHIWxvR2_N"
   },
   "source": [
    "Training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5CZ0jJxR1e1"
   },
   "outputs": [],
   "source": [
    "# downscale_factor = 4\n",
    "# image_shape =(192,192,3) #need to be modified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hm9KTnBoSB0o"
   },
   "outputs": [],
   "source": [
    "# Overall gan network\n",
    "def gan_network(discriminator,shape, generator, optimizer,vgg_loss):\n",
    "    gan_input= Input(shape=shape)\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    image_sr = generator(gan_input)\n",
    "    \n",
    "    \n",
    "    gan_output = discriminator(image_sr)\n",
    "    gan = Model(inputs = [gan_input],outputs = [gan_output])\n",
    "    gan.compile(loss =[vgg_loss, \"binary_crossentropy\"],loss_weights =[1., 1e-3] , optimizer = optimizer)\n",
    "    print(gan.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "laR_6O3YSDkl"
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "downscale_factor = 4\n",
    "\n",
    "image_shape =(192,192,3) #need to be modified \n",
    "\n",
    "def train(epochs, batch_size):\n",
    "   x_train_hr, x_train_lr = train_data_load()             #load data \n",
    "   loss = VGG_LOSS(image_shape)\n",
    "\n",
    "   batch_count = int(x_train_hr.shape[0]/batch_size)\n",
    "   shape = (image_shape[0] // downscale_factor, image_shape[1] // downscale_factor, image_shape[2]//downscale_factor)\n",
    "   generator = gen(shape).generator()\n",
    "   discriminator = dis(image_shape).discriminator()\n",
    "  \n",
    "   optimizer = optimizer()\n",
    "\n",
    "   generator.compile(loss=loss.vgg_loss,optimizer = optimizer )\n",
    "   discriminator.compile(loss ='binary_crossentropy',optimizer= optimizer)\n",
    "\n",
    "   gan =gan_network(discriminator,shape,generator, optimizer,loss.vgg_loss)\n",
    "\n",
    "\n",
    "   for e in range(1,epochs+1):\n",
    "     print('Epoch{}/{}'.format(e+1,epochs+1))\n",
    "     for _ in tqdm(range(batch_count)):\n",
    "    #  generates random integer between 0 and x_train_hr.shape[0] of the size batch_size\n",
    "       rand_num = np.random.randint(0,x_train_hr.shape[0],size=batch_size)\n",
    "\n",
    "       image_batch_hr = x_train_hr[rand_num]\n",
    "       image_batch_lr = x_train_lr[rand_num]\n",
    "\n",
    "       generated_images_sr = generator.predict(image_batch_lr)\n",
    "\n",
    "       real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
    "       fake_data_y = np.random.random_sample(batch_size)*0.2\n",
    "\n",
    "       discriminator.trainable = True \n",
    "\n",
    "      # calculate discriminator loss\n",
    "\n",
    "       d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
    "       d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_y)\n",
    "       dis_loss = 0.5*np.add(d_loss_real,d_loss_fake)\n",
    "\n",
    "    #  calculate gan loss\n",
    "       rand_num = np.random.randint(0,x_train_hr.shape[0],size=batch_size)\n",
    "\n",
    "     \n",
    "       image_batch_hr = x_train_hr[rand_num]\n",
    "       image_batch_lr = x_train_lr[rand_num]\n",
    "\n",
    "       gan_Y = np.random.random_sample(batch_size)*0.2\n",
    "       discriminator.trainable = False\n",
    "\n",
    "       gan_loss = gan.train_on_batch(image_batch_lr,[])\n",
    "\n",
    "     print(\"discriminator_loss: %f\", dis_loss)\n",
    "     print(\"gan_loss\", gan_loss)\n",
    "    # gan_loss = str(gan_loss)\n",
    "\n",
    "     if e ==1 or e % 5 ==0:\n",
    "       preprocessing.plot_generated_images(e,generator,x_test_hr,x_test_lr)\n",
    "     if e % 300 == 0:\n",
    "       generator.save(\"/content/drive/My Drive/Colab Notebooks/project/Output/gen_model%d.h5\" %e)\n",
    "       discriminator.save(\"/content/drive/My Drive/Colab Notebooks/project/Output/dis_model%d.h5\" %e)\n",
    "       gan.save(\"/content/drive/My Drive/Colab Notebooks/project/Output/gan_model%d.h5\" %e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4cAV27USGtz"
   },
   "outputs": [],
   "source": [
    "train(200,4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SISR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
