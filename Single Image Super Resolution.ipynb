{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Lambda, Input, add, Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.core import Flatten\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.transform\n",
    "from skimage import data, io, filters\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "HR and LR images in the form of a numpy array from a given list of images.\n",
    "\n",
    "Low resolution images are down scaled by 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    \n",
    "    train_path = './data/train/'\n",
    "    test_path = './data/test/'\n",
    "\n",
    "    train_data = os.listdir(train_path)\n",
    "    test_data = os.listdir(test_path)\n",
    "    \n",
    "    for sample in train_data:\n",
    "        img_path = train_path + sample\n",
    "        train_hr_images = cv2.imread(img_path)\n",
    "        train_images.append(train_hr_images)\n",
    "\n",
    "    for sample in test_data:\n",
    "        img_path = test_path + sample\n",
    "        test_hr_images = cv2.imread(img_path)\n",
    "        test_images.append(test_hr_images)\n",
    "    \n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def hr_images(images):\n",
    "    images_hr = array(images)\n",
    "    return images_hr\n",
    "\n",
    "def lr_images(images_real, downscale):\n",
    "    images = []\n",
    "    for img in range(len(images_real)):\n",
    "        images.append(np.array(PIL.Image.fromarray(images_real[img]).resize([images_real[img].shape[0]//downscale, images_real[img].shape[1]//downscale],resample=PIL.Image.BICUBIC)))\n",
    "    images_lr = array(images)\n",
    "    return images_lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range of HR and LR images\n",
    "\n",
    "The range of LR input images is scaled to [0, 1]\n",
    "\n",
    "The range of HR input images is scaled to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The MSE loss was thus calculated on images of intensity range [-1, 1]. VGG feature maps were also rescaled by a factor of 1/12.75\n",
    " to obtain VGG losses of a scale that is comparable to the MSE loss.'''\n",
    "\n",
    "#function to scale HR images to range [-1, 1]\n",
    "def preprocess_HR(x):\n",
    "    return np.divide(x.astype(np.float32), 127.5) - np.ones_like(x, dtype=np.float32)\n",
    "\n",
    "def deprocess_HR(x):\n",
    "    input_data = (input_data + 1) * 127.5\n",
    "    return input_data.astype(np.unit8)\n",
    "\n",
    "#function to scale LR images to range [0, 1]\n",
    "def preprocess_LR(x):\n",
    "    return np.divide(x.astype(np.float), 255.)\n",
    "\n",
    "#Unable to understand the reason behind the use of this function\n",
    "def deprocess_LR(x):\n",
    "    x = np.clip(x*255, 0, 255)\n",
    "    return x.astype(np.unit8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1024, 3)\n",
      "(256, 180, 3)\n",
      "(720, 1024, 3)\n",
      "(256, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = load_images()\n",
    "\n",
    "x_train_hr = hr_images(x_train)\n",
    "x_train_hr = preprocess_HR(x_train_hr)\n",
    "\n",
    "x_train_lr = lr_images(x_train, 4)\n",
    "x_train_lr = preprocess_LR(x_train_lr)\n",
    "\n",
    "x_test_hr = hr_images(x_test)\n",
    "x_test_hr = preprocess_HR(x_test_hr)\n",
    "\n",
    "x_test_lr = lr_images(x_test, 4)\n",
    "x_test_lr = preprocess_LR(x_test_lr)\n",
    "\n",
    "print(x_train_hr[4].shape)\n",
    "print(x_train_lr[4].shape)\n",
    "print(x_test_hr[1].shape)\n",
    "print(x_test_lr[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network\n",
    "Number of Residual blocks used are 16.\n",
    "\n",
    "Number of up-sampling blocks are 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block_gen(model, kernel_size, filters, strides):\n",
    " \n",
    "    generator = model\n",
    "    \n",
    "    model = Conv2D(filters, kernel_size = kernel_size,strides = strides, padding = 'same')(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "    model = PReLU(alpha_initializer = \"zeros\", alpha_regularizer = None, alpha_constraint = None, shared_axes=[1,2])(model)\n",
    "    model = Conv2D(filters, kernel_size = kernel_size, strides = strides, padding = 'same')(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "    \n",
    "    model = add([generator, model])\n",
    "    \n",
    "    return generator\n",
    "\n",
    "def up_sampling_block(model, kernel_size, filters, strides):\n",
    "    \n",
    "    model = Conv2D(filters, kernel_size = kernel_size, strides = strides, padding = 'same')(model)\n",
    "    model = UpSampling2D(size = 2)(model)\n",
    "    model = LeakyReLU(alpha = 0.2)(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "class Generator(object):\n",
    "    \n",
    "    def __init__(self, noise_shape):\n",
    "        self.noise_shape = noise_shape\n",
    "        \n",
    "    def generator(self):\n",
    "        gen_input = Input(shape = self.noise_shape)\n",
    "        \n",
    "        model = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n",
    "        model =  PReLU(alpha_initializer = 'zeros', alpha_regularizer = None, alpha_constraint=None, shared_axes = [1,2])(model)\n",
    "        \n",
    "        gen_model = model\n",
    "        \n",
    "        for index in range(16):\n",
    "            model = res_block_gen(model, 3, 64, 1)\n",
    "            \n",
    "        model = Conv2D(filters = 64, kernel_size =3, strides = 1, padding = \"same\")(model)\n",
    "        model = BatchNormalization(momentum = 0.5)(model)\n",
    "        \n",
    "        model = add([gen_model, model])\n",
    "        \n",
    "        for index in range(2):\n",
    "            model = up_sampling_block(model, 3, 256, 1)\n",
    "                \n",
    "        model = Conv2D(filters = 64, kernel_size =9, strides = 1, padding = \"same\")(model)\n",
    "        model = Activation('tanh')(model)\n",
    "        \n",
    "        generator_model = Model(inputs = gen_input, outputs = model)\n",
    "        \n",
    "        return generator_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Discriminator is use to distinguish the HR images and back-propagate the GAN loss to train the discriminator and the generator'''\n",
    "\n",
    "def discriminator_block(model, filters, kernel_size, strides):\n",
    "    \n",
    "    model = Conv2D(filters, kernel_size = kernel_size, strides = strides, padding = 'same')(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "    model = LeakyReLU(alpha = 0.2)(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "class Discriminator(object):\n",
    "    \n",
    "    def __init__(self, image_shape):\n",
    "        self.image_shape = image_shape\n",
    "        \n",
    "    def discriminator(self):\n",
    "        \n",
    "        dis_input = Input(shape = self.image_shape)\n",
    "        \n",
    "        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n",
    "        model = LeakyReLU(alpha = 0.2)(model)\n",
    "        \n",
    "        model = discriminator_block(model, 64, 3, 2)\n",
    "        model = discriminator_block(model, 128, 3, 1)\n",
    "        model = discriminator_block(model, 128, 3, 2)\n",
    "        model = discriminator_block(model, 256, 3, 1)\n",
    "        model = discriminator_block(model, 256, 3, 2)\n",
    "        model = discriminator_block(model, 512, 3, 1)\n",
    "        model = discriminator_block(model, 512, 3, 2)\n",
    "\n",
    "        model = Flatten()(model)\n",
    "        model = Dense(1024)(model)\n",
    "        model = LeakyReLU(alpha = 0.2)(model)\n",
    "        \n",
    "        model = Dense(1)(model)\n",
    "        model = Activation('sigmoid')(model)\n",
    "        \n",
    "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
    "        \n",
    "        return discriminator_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Loss Function\n",
    "\n",
    "Compares the outputs of the first convolutionns of VGG.\n",
    "\n",
    "This loss ensures the GAN model is oriented towards a deblurring task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    " def vgg_loss(self, y_true, y_pred):\n",
    "        \n",
    "        vgg19 = VGG19(include_top = False, weights = \"imagenet\", input_shape = self.image_shape)\n",
    "        vgg19.trainable = False\n",
    "        \n",
    "        for l in vgg19.layers:\n",
    "            l.trainable = False\n",
    "        \n",
    "        loss_model = Model(inputs = vgg19.input, outputs = vgg19.get_layer('block5_conv4').output)\n",
    "        loss_model.trainable = False\n",
    "        \n",
    "# '''vgg_loss here represents the MSE(Mean Square Error) of features extracted by a VGG-19 network. For a \n",
    "#    specific layer within VGG-19, we want their features to be matched (Minimum MSE for features)'''\n",
    "        \n",
    "        vgg_loss = K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
    "       \n",
    "        \n",
    "        return vgg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and Discriminator combined\n",
    "Two loss used, content loss defined above and Adversarial loss(Binary cross-entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
    "    \n",
    "    discriminator.trainable = False #Why is the disciminator parameters not to be trained?\n",
    "    \n",
    "    gan_input = Input(shape = shape)#Why is here this input?\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(inputs = gan_input, outputs=[x,gan_output])\n",
    "    #Compiled GAN network with VGG loss and binary crossentropy loss\n",
    "    gan.compile(loss = [vggloss, \"binary_crossentropy\"], loss_weights = [1., 1e-3], optimizer = optimizer )\n",
    "    \n",
    "    return gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Function\n",
    "Adam optimizer with *B1* = 0.9, *B2* = 0.999  and learning rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer():\n",
    "    \n",
    "    adam = Adam(lr = 0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08) \n",
    "    return adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to plot the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     rand_nums = np.random.randint(0, 5, size = 3)\n",
    "#     print(rand_nums)\n",
    "\n",
    "def plot_generated_images(epoch, generator, examples = 3, dim = (1, 3), figsize = (15, 5)):\n",
    "    \n",
    "    rand_nums = np.random.randint(0, x_test_hr.shape[0], size = examples)\n",
    "    \n",
    "    image_batch_hr = denormalize(x_test_hr[rand_nums])\n",
    "    image_batch_lr = x_test_lr[rand_nums]\n",
    "   \n",
    "    gen_image = generator.oredict(image_batch_lr)\n",
    "    generated_image = denormalize(gen_img)\n",
    "    image_batch_lr = denormalize(image_batch_lr)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    plt.subplot(dim[0], dim[1], 1)\n",
    "    plt.imshow(image_batch_lr[1], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "        \n",
    "    plt.subplot(dim[0], dim[1], 2)\n",
    "    plt.imshow(generated_image[1], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(dim[0], dim[1], 3)\n",
    "    plt.imshow(image_batch_hr[1], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/gan_generated_image_epoch_%d.png' % epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "image_shape = (384, 384, 3)\n",
    "\n",
    "def train(epochs, batch_size):\n",
    "    \n",
    "    downscale_factor = 4\n",
    "    \n",
    "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
    "    shape=(image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
    "    \n",
    "    generator = Generator(shape).generator()\n",
    "    discriminator = Discriminator(image_shape).discriminator()\n",
    "    \n",
    "    adam = get_optimizer()\n",
    "    generator.compile(loss = vgg_loss, optimizer = adam)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer = adam)\n",
    "    \n",
    "    gan = get_gan_network(discriminator, shape, generator, adam)\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        print('-'*15, 'Epoch %d' %e, '-'*15)\n",
    "        \n",
    "        for _ in range(batch_count):\n",
    "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size = batch_size)\n",
    "            \n",
    "            image_batch_hr = x_train_hr[rand_nums]\n",
    "            image_batch_lr = x_train_lr[rand_nums]\n",
    "            generated_images_sr = generator.predict(image_batch_lr)\n",
    "            \n",
    "            real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size) * 0.2\n",
    "            fake_data_Y = np.random.random_sample(batch_size) * 0.2\n",
    "            \n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
    "            \n",
    "            gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size) * 0.2\n",
    "            discriminator.trainable = False\n",
    "            \n",
    "            loss_gan = gan.train_on_batch(image_batch_lr, [image_batch_hr, gan_Y])\n",
    "            \n",
    "            print(\"Loss HR, Loss LR, Loss GAN\")\n",
    "            print(d_loss_real, d_loss_fake, loss_gan)\n",
    "            \n",
    "            if (e == 1 or e%5 == 0):\n",
    "                plot_generated_images(e, generator)\n",
    "            if(e % 300 == 0 ):\n",
    "                generator.save('./output/gen_model%d.h5' % e)\n",
    "                discriminator.save('./output/dis_model%d.h5' % e)\n",
    "                gan.save('./output/gan_model%d.h5' % e)\n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[294912,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-72b11f87bd6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-ab00d1535cef>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs, batch_size)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdiscriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-83-aefd87038929>\u001b[0m in \u001b[0;36mdiscriminator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m                                          \u001b[1;34m'You can build it manually via: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m--> 463\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    893\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m             self.bias = self.add_weight(shape=(self.units,),\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         weight = K.variable(initializer(shape, dtype=dtype),\n\u001b[0m\u001b[0;32m    280\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m                             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             x = K.random_uniform(shape, -limit, limit,\n\u001b[1;32m--> 227\u001b[1;33m                                  dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[0;32m   4355\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         return tf_keras_backend.random_uniform(\n\u001b[1;32m-> 4357\u001b[1;33m             shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[0;32m   5684\u001b[0m     \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5685\u001b[0m   return random_ops.random_uniform(\n\u001b[1;32m-> 5686\u001b[1;33m       shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n\u001b[0m\u001b[0;32m   5687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    299\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m     \u001b[1;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6652\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6653\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6654\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\valkyrie\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[294912,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]"
     ]
    }
   ],
   "source": [
    "train(20000,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
