{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from numpy import array\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D\n",
    "from keras.models import Model\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from skimage.transform import rescale, resize\n",
    "# from scipy.misc import imresize\n",
    "import PIL\n",
    "\n",
    "# from keras.layers import \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "HR and LR images in the form of a numpy array from a given list of images.\n",
    "\n",
    "Low resolution images are down scaled by 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1024, 3)\n",
      "(256, 180, 3)\n",
      "(720, 1024, 3)\n",
      "(256, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_images():\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    \n",
    "    train_path = './dataset/train/'\n",
    "    test_path = './dataset/test/'\n",
    "\n",
    "    train_data = os.listdir(train_path)\n",
    "    test_data = os.listdir(test_path)\n",
    "    \n",
    "    for sample in train_data:\n",
    "        img_path = train_path + sample\n",
    "        train_hr_images = cv2.imread(img_path)\n",
    "        train_images.append(train_hr_images)\n",
    "\n",
    "    for sample in test_data:\n",
    "        img_path = test_path + sample\n",
    "        test_hr_images = cv2.imread(img_path)\n",
    "        test_images.append(test_hr_images)\n",
    "    \n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def hr_images(images):\n",
    "    images_hr = array(images)\n",
    "    return images_hr\n",
    "\n",
    "def lr_images(images_real, downscale):\n",
    "    images = []\n",
    "    for img in range(len(images_real)):\n",
    "        images.append(np.array(PIL.Image.fromarray(images_real[img]).resize([images_real[img].shape[0]//downscale, images_real[img].shape[1]//downscale],resample=PIL.Image.BICUBIC)))\n",
    "    images_lr = array(images)\n",
    "    return images_lr\n",
    "\n",
    "x_train, x_test = load_images()\n",
    "\n",
    "x_train_hr = hr_images(x_train)\n",
    "x_train_lr = lr_images(x_train, 4)\n",
    "x_test_hr = hr_images(x_test)\n",
    "x_test_lr = lr_images(x_test, 4)\n",
    "\n",
    "print(x_train_hr[4].shape)\n",
    "print(x_train_lr[4].shape)\n",
    "print(x_test_hr[1].shape)\n",
    "print(x_test_lr[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network\n",
    "Number of Residual blocks used are 16.\n",
    "\n",
    "Number of up-sampling blocks are 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block_gen(model, kernel_size, filters, strides):\n",
    " \n",
    "    generator = model\n",
    "    \n",
    "    generator.add(Conv2D(filters, kernel_size = kernel_size, filters = filters, strides = strides, padding = 'same'))\n",
    "    generator.add(BatchNormalization(momentum = 0.5))\n",
    "    generator.add(PReLU(alpha_initializer = \"zeros\", alpha_regularizer = None, alpha_constraint = None, shared_axes=[1,2]))\n",
    "    generator.add(Conv2D(filters, kernel_size = kernel_size, filters = filters, strides = strides, padding = 'same'))\n",
    "    generator.add(BatchNormalization(momentum = 0.5))\n",
    "    \n",
    "    return generator\n",
    "\n",
    "def up_sampling_block(model, kernel_size, filters, strides):\n",
    "    \n",
    "    model.add(Conv2D(filters, kernel_size = kernel_size, filters = filters, strides = strides, padding = 'same'))\n",
    "    model.add(UpSampling(size = 2))\n",
    "    model.add(LeakyRelU(alpha = 0.2))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "class Generator(object):\n",
    "    \n",
    "    def __init__(self, noise_shape):\n",
    "        self.noise_shape = noise_shape\n",
    "        \n",
    "    def generator(self):\n",
    "        gen_input = Input(shape = self.noise_shape)\n",
    "        \n",
    "        model = gen_input.add(Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\"))\n",
    "        model.add(PReLU(alpha_initializers = 'zeros', alpha_regularizer = None, shared_axes = [1,2] ))\n",
    "        \n",
    "        gen_model = model\n",
    "        \n",
    "        for index in range(16):\n",
    "            model = res_block_gen(model, 3, 64, 1)\n",
    "            \n",
    "        model.add(Conv2D(filters = 64, kernel_size =3, strides = 1, padding = \"same\"))\n",
    "        model.add(BatchNormalization(momentum = 0.5))\n",
    "        \n",
    "        model.add(gen_input)\n",
    "        \n",
    "        for index in range(2):\n",
    "            model = up_smapling_block(model, 3, 256, 1)\n",
    "                \n",
    "        model.add(Conv2D(filters = 64, kernel_size =9, strides = 1, padding = \"same\"))\n",
    "        model.add(Activation('tanh'))\n",
    "        \n",
    "        generator_model = Model(inputs = gen_input, outputs = model)\n",
    "        \n",
    "        return generator_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Discriminator is use to distinguish the HR images and back-propagate the GAN loss to train the discriminator and the generator'''\n",
    "\n",
    "def discriminator_block(model, filters, kernel_size, strides):\n",
    "    \n",
    "    model.add(Conv2D(filters, kernel_size = kernel_size, strides = strides, padding = 'same'))\n",
    "    model.add(BatchNormalization(momentum = 0.5))\n",
    "    model.add(LeakyRelU(alpha = 0.2))\n",
    "    \n",
    "    return model\n",
    "\n",
    "class Discriminator(object):\n",
    "    \n",
    "    def __init__(self, image_shape):\n",
    "        self.image_shape = image_shape\n",
    "        \n",
    "    def Discriminator(self):\n",
    "        \n",
    "        dis_input = Input(shape = self.image_shape)\n",
    "        \n",
    "        model = dis_input.add(Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\"))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        model = discriminator_block(model, 64, 3, 2)\n",
    "        model = discriminator_block(model, 128, 3, 1)\n",
    "        model = discriminator_block(model, 128, 3, 2)\n",
    "        model = discriminator_block(model, 256, 3, 1)\n",
    "        model = discriminator_block(model, 256, 3, 2)\n",
    "        model = discriminator_block(model, 512, 3, 1)\n",
    "        model = discriminator_block(model, 512, 3, 2)\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        model.add(Dense(1))\n",
    "        model.Activation('sigmoid')\n",
    "        \n",
    "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
    "        \n",
    "        return discriminator_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Loss Function\n",
    "\n",
    "Compares the outputs of the first convolutionns of VGG.\n",
    "\n",
    "This loss ensures the GAN model is oriented towards a deblurring task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def vgg_loss(self, y_true, y_pred):\n",
    "        \n",
    "        vgg19 = VGG19(include_top = False, weights = \"imagenet\", input_shape = self.image_shape)\n",
    "        vgg19.trainable = False\n",
    "        \n",
    "        for l in vgg19.layers:\n",
    "            l.trainable = False\n",
    "        \n",
    "        loss_model = Model(inputs = vgg19.input, outputs = vgg19.get_layer('block5_conv4').output)\n",
    "        loss_model.trainable = False\n",
    "        \n",
    "'''vgg_loss here represents the MSE(Mean Square Error) of features extracted by a VGG-19 network. For a \n",
    "   specific layer within VGG-19, we want their features to be matched (Minimum MSE for features)'''\n",
    "       \n",
    "        vgg_loss = K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
    "        return vgg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and Discriminator combined\n",
    "Two loss used, content loss defined above and Adversarial loss(Binary cross-entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
    "    \n",
    "    discriminator.trainable = False #Why is the disciminator parameters not to be trained?\n",
    "    \n",
    "    gan_input = Input(shape = shape)#Why is here this input?\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(inputs = gan_input, outputs=[x,gan_output])\n",
    "    #Compiled GAN network with VGG loss and binary crossentropy loss\n",
    "    gan.compile(loss = [vggloss, \"binary_crossentropy\"], loss_weights = [1., 1e-3], optimizer = optimizer )\n",
    "    \n",
    "    return gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Function\n",
    "Adam optimizer with *B1* = 0.9, *B2* = 0.999  and learning rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer():\n",
    "    \n",
    "    adam = Adam(lr = 0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08) \n",
    "    return adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "image_shape(384, 384, 3)\n",
    "\n",
    "def train(epochs, batch_size):\n",
    "    \n",
    "    downscale_factor = 4\n",
    "    \n",
    "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
    "    shape=(image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
    "    \n",
    "    generator = Generator(shape).generator()\n",
    "    discriminator = Discriminator(image_shape).discriminator()\n",
    "    \n",
    "    adam = get_optimizer()\n",
    "    generator.compile(loss = vgg_loss, optimizer = adam)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer = adam)\n",
    "    \n",
    "    gan = get_gan_network(discriminator, shape, generator, adam)\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
