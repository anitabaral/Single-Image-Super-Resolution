{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "HR and LR images in the form of a numpy array from a given list of images.\n",
    "\n",
    "Low resolution images are down scaled by 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    \n",
    "    train_path = './data/train/'\n",
    "    test_path = './data/test/'\n",
    "\n",
    "    train_data = os.listdir(train_path)\n",
    "    test_data = os.listdir(test_path)\n",
    "    \n",
    "    for sample in train_data:\n",
    "        img_path = train_path + sample\n",
    "        train_hr_images = cv2.imread(img_path)\n",
    "        train_images.append(train_hr_images)\n",
    "\n",
    "    for sample in test_data:\n",
    "        img_path = test_path + sample\n",
    "        test_hr_images = cv2.imread(img_path)\n",
    "        test_images.append(test_hr_images)\n",
    "    \n",
    "    return train_images, test_images\n",
    "\n",
    "\n",
    "def hr_images(images):\n",
    "    images_hr = array(images)\n",
    "    return images_hr\n",
    "\n",
    "def lr_images(images_real, downscale):\n",
    "    images = []\n",
    "    for img in range(len(images_real)):\n",
    "        images.append(np.array(PIL.Image.fromarray(images_real[img]).resize([images_real[img].shape[0]//downscale, images_real[img].shape[1]//downscale],resample=PIL.Image.BICUBIC)))\n",
    "    images_lr = array(images)\n",
    "    return images_lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range of HR and LR images\n",
    "\n",
    "The range of LR input images is scaled to [0, 1]\n",
    "\n",
    "The range of HR input images is scaled to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The MSE loss was thus calculated on images of intensity range [-1, 1]. VGG feature maps were also rescaled by a factor of 1/12.75\n",
    " to obtain VGG losses of a scale that is comparable to the MSE loss.'''\n",
    "\n",
    "#function to scale HR images to range [-1, 1]\n",
    "def preprocess_HR(x):\n",
    "    return np.divide(x.astype(np.float32), 127.5) - np.ones_like(x, dtype=np.float32)\n",
    "\n",
    "def deprocess_HR(x):\n",
    "    input_data = (input_data + 1) * 127.5\n",
    "    return input_data.astype(np.unit8)\n",
    "\n",
    "#function to scale LR images to range [0, 1]\n",
    "def preprocess_LR(x):\n",
    "    return np.divide(x.astype(np.float), 255.)\n",
    "\n",
    "#Unable to understand the reason behind the use of this function\n",
    "def deprocess_LR(x):\n",
    "    x = np.clip(x*255, 0, 255)\n",
    "    return x.astype(np.unit8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1024, 3)\n",
      "(256, 180, 3)\n",
      "(720, 1024, 3)\n",
      "(256, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = load_images()\n",
    "\n",
    "x_train_hr = hr_images(x_train)\n",
    "x_train_hr = preprocess_HR(x_train_hr)\n",
    "\n",
    "x_train_lr = lr_images(x_train, 4)\n",
    "x_train_lr = preprocess_LR(x_train_lr)\n",
    "\n",
    "x_test_hr = hr_images(x_test)\n",
    "x_test_hr = preprocess_HR(x_test_hr)\n",
    "\n",
    "x_test_lr = lr_images(x_test, 4)\n",
    "x_test_lr = preprocess_LR(x_test_lr)\n",
    "\n",
    "print(x_train_hr[4].shape)\n",
    "print(x_train_lr[4].shape)\n",
    "print(x_test_hr[1].shape)\n",
    "print(x_test_lr[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network\n",
    "Number of Residual blocks used are 16.\n",
    "\n",
    "Number of up-sampling blocks are 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block_gen(model, kernel_size, filters, strides):\n",
    " \n",
    "    generator = model\n",
    "    \n",
    "    generator.add(Conv2D(filters, kernel_size = kernel_size, filters = filters, strides = strides, padding = 'same'))\n",
    "    generator.add(BatchNormalization(momentum = 0.5))\n",
    "    generator.add(PReLU(alpha_initializer = \"zeros\", alpha_regularizer = None, alpha_constraint = None, shared_axes=[1,2]))\n",
    "    generator.add(Conv2D(filters, kernel_size = kernel_size, filters = filters, strides = strides, padding = 'same'))\n",
    "    generator.add(BatchNormalization(momentum = 0.5))\n",
    "    \n",
    "    return generator\n",
    "\n",
    "def up_sampling_block(model, kernel_size, filters, strides):\n",
    "    \n",
    "    model.add(Conv2D(filters, kernel_size = kernel_size, filters = filters, strides = strides, padding = 'same'))\n",
    "    model.add(UpSampling(size = 2))\n",
    "    model.add(LeakyRelU(alpha = 0.2))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "class Generator(object):\n",
    "    \n",
    "    def __init__(self, noise_shape):\n",
    "        self.noise_shape = noise_shape\n",
    "        \n",
    "    def generator(self):\n",
    "        gen_input = Input(shape = self.noise_shape)\n",
    "        \n",
    "        model = gen_input.add(Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\"))\n",
    "        model.add(PReLU(alpha_initializers = 'zeros', alpha_regularizer = None, shared_axes = [1,2] ))\n",
    "        \n",
    "        gen_model = model\n",
    "        \n",
    "        for index in range(16):\n",
    "            model = res_block_gen(model, 3, 64, 1)\n",
    "            \n",
    "        model.add(Conv2D(filters = 64, kernel_size =3, strides = 1, padding = \"same\"))\n",
    "        model.add(BatchNormalization(momentum = 0.5))\n",
    "        \n",
    "        model.add(gen_input)\n",
    "        \n",
    "        for index in range(2):\n",
    "            model = up_smapling_block(model, 3, 256, 1)\n",
    "                \n",
    "        model.add(Conv2D(filters = 64, kernel_size =9, strides = 1, padding = \"same\"))\n",
    "        model.add(Activation('tanh'))\n",
    "        \n",
    "        generator_model = Model(inputs = gen_input, outputs = model)\n",
    "        \n",
    "        return generator_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Discriminator is use to distinguish the HR images and back-propagate the GAN loss to train the discriminator and the generator'''\n",
    "\n",
    "def discriminator_block(model, filters, kernel_size, strides):\n",
    "    \n",
    "    model.add(Conv2D(filters, kernel_size = kernel_size, strides = strides, padding = 'same'))\n",
    "    model.add(BatchNormalization(momentum = 0.5))\n",
    "    model.add(LeakyRelU(alpha = 0.2))\n",
    "    \n",
    "    return model\n",
    "\n",
    "class Discriminator(object):\n",
    "    \n",
    "    def __init__(self, image_shape):\n",
    "        self.image_shape = image_shape\n",
    "        \n",
    "    def Discriminator(self):\n",
    "        \n",
    "        dis_input = Input(shape = self.image_shape)\n",
    "        \n",
    "        model = dis_input.add(Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\"))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        model = discriminator_block(model, 64, 3, 2)\n",
    "        model = discriminator_block(model, 128, 3, 1)\n",
    "        model = discriminator_block(model, 128, 3, 2)\n",
    "        model = discriminator_block(model, 256, 3, 1)\n",
    "        model = discriminator_block(model, 256, 3, 2)\n",
    "        model = discriminator_block(model, 512, 3, 1)\n",
    "        model = discriminator_block(model, 512, 3, 2)\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        model.add(Dense(1))\n",
    "        model.Activation('sigmoid')\n",
    "        \n",
    "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
    "        \n",
    "        return discriminator_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Loss Function\n",
    "\n",
    "Compares the outputs of the first convolutionns of VGG.\n",
    "\n",
    "This loss ensures the GAN model is oriented towards a deblurring task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def vgg_loss(self, y_true, y_pred):\n",
    "        \n",
    "        vgg19 = VGG19(include_top = False, weights = \"imagenet\", input_shape = self.image_shape)\n",
    "        vgg19.trainable = False\n",
    "        \n",
    "        for l in vgg19.layers:\n",
    "            l.trainable = False\n",
    "        \n",
    "        loss_model = Model(inputs = vgg19.input, outputs = vgg19.get_layer('block5_conv4').output)\n",
    "        loss_model.trainable = False\n",
    "        \n",
    "'''vgg_loss here represents the MSE(Mean Square Error) of features extracted by a VGG-19 network. For a \n",
    "   specific layer within VGG-19, we want their features to be matched (Minimum MSE for features)'''\n",
    "       \n",
    "        vgg_loss = K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
    "        return vgg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and Discriminator combined\n",
    "Two loss used, content loss defined above and Adversarial loss(Binary cross-entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gan_network(discriminator, shape, generator, optimizer, vgg_loss):\n",
    "    \n",
    "    discriminator.trainable = False #Why is the disciminator parameters not to be trained?\n",
    "    \n",
    "    gan_input = Input(shape = shape)#Why is here this input?\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(inputs = gan_input, outputs=[x,gan_output])\n",
    "    #Compiled GAN network with VGG loss and binary crossentropy loss\n",
    "    gan.compile(loss = [vggloss, \"binary_crossentropy\"], loss_weights = [1., 1e-3], optimizer = optimizer )\n",
    "    \n",
    "    return gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Function\n",
    "Adam optimizer with *B1* = 0.9, *B2* = 0.999  and learning rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer():\n",
    "    \n",
    "    adam = Adam(lr = 0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08) \n",
    "    return adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to plot the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(epoch, generator, examples = 3, dim = (1, 3), figsize = (15, 5)):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "image_shape(384, 384, 3)\n",
    "\n",
    "def train(epochs, batch_size):\n",
    "    \n",
    "    downscale_factor = 4\n",
    "    \n",
    "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
    "    shape=(image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
    "    \n",
    "    generator = Generator(shape).generator()\n",
    "    discriminator = Discriminator(image_shape).discriminator()\n",
    "    \n",
    "    adam = get_optimizer()\n",
    "    generator.compile(loss = vgg_loss, optimizer = adam)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer = adam)\n",
    "    \n",
    "    gan = get_gan_network(discriminator, shape, generator, adam)\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        print('-'*15, 'Epoch %d' %e, '-'*15)\n",
    "        \n",
    "        for _ in range(batch_count):\n",
    "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size = batch_size)\n",
    "            \n",
    "            image_batch_hr = x_train_hr[rand_nums]\n",
    "            image_batch_lr = x_train_lr[rand_nums]\n",
    "            generated_images_sr = generator.predict(image_batch_lr)\n",
    "            \n",
    "            real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size) * 0.2\n",
    "            fake_data_Y = np.random.random_sample(batch_size) * 0.2\n",
    "            \n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
    "            \n",
    "            gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size) * 0.2\n",
    "            discriminator.trainable = False\n",
    "            \n",
    "            loss_gan = gan.train_on_batch(image_batch_lr, [image_batch_hr, gan_Y])\n",
    "            \n",
    "            print(\"Loss HR, Loss LR, Loss GAN\")\n",
    "            print(d_loss_real, d_loss_fake, loss_gan)\n",
    "            \n",
    "            if (e == 1 or e%5 == 0):\n",
    "                plot_generated_images(e, generator)\n",
    "            if(e % 300 == 0 ):\n",
    "                generator.save('./output/gen_model%d.h5' % e)\n",
    "                discriminator.save('./output/dis_model%d.h5' % e)\n",
    "                gan.save('./output/gan_model%d.h5' % e)\n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(20000,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
